{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNuuoR7JnaK8"
   },
   "source": [
    "# **Loading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4RI7CNnAFBN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "jIg5bLW1I-ba",
    "outputId": "4387afc5-9758-4ad8-ac5b-4707373ac9bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-aaafb60e-dd7c-452e-b5dd-9c05de63587c\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-aaafb60e-dd7c-452e-b5dd-9c05de63587c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data_train.pkl to data_train (2).pkl\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     result = _output.eval_js(\n\u001b[1;32m     71\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[0;32m---> 72\u001b[0;31m             output_id=output_id))\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'append'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0;31m# JS side uses a generator of promises to process all of the files- some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vCZzVeilBGpB"
   },
   "outputs": [],
   "source": [
    "train_data = np.load('data_train.pkl', allow_pickle=True)\n",
    "test_data = np.load('data_test.pkl', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x1BKDsE-DodJ"
   },
   "source": [
    "# **Data exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "IyPaAZkyDuhP",
    "outputId": "29224d0b-c6d5-4691-d3a1-fcbd8470dfe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70000 samples\n",
      "There are 20 classes\n",
      "There are 3500 samples per class\n",
      "The median of words per sample is 25\n",
      "The number of samples/number of words per sample ratio is 2800.0\n"
     ]
    }
   ],
   "source": [
    "#number of samples\n",
    "print(\"There are\",len(train_data[0]),\"samples\" )\n",
    "#number of classes\n",
    "print(\"There are\", len(np.unique(train_data[1])), \"classes\")\n",
    "#number of samples per class\n",
    "samples_per_class = np.zeros((20))\n",
    "for index, subreddit in enumerate(np.unique(train_data[1])):\n",
    "  for i in range(len(train_data[1])):\n",
    "    if train_data[1][i] == subreddit:\n",
    "      samples_per_class[index] += 1   \n",
    "\n",
    "print(\"There are\", 3500, \"samples per class\")\n",
    "\n",
    "#median number of words per sample\n",
    "def num_words_per_sample(sample_texts):\n",
    "  num_words = [len(s.split()) for s in sample_texts]\n",
    "  return np.median(num_words)\n",
    "\n",
    "print(\"The median of words per sample is\", int(num_words_per_sample(train_data[0])))\n",
    "\n",
    "print(\"The number of samples/number of words per sample ratio is\", len(train_data[0])/ num_words_per_sample(train_data[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "prELx7lkngAT"
   },
   "source": [
    "# **Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiTCybDIZh4n"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(reddit_train_x, reddit_test_x, reddit_train_y, reddit_test_y) = train_test_split(train_data[0], train_data[1], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJu8qNttR2Yo"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "top_k = 35000\n",
    "\n",
    "def ngram_vectorize(training_comments, training_labels, testing_comments):\n",
    "  vectorizer = TfidfVectorizer(decode_error='replace', strip_accents='unicode', stop_words='english', ngram_range=(1,2), analyzer='word', min_df=2)\n",
    "\n",
    "  # Learn vocabulary from training texts and vectorize training texts\n",
    "  x_train = vectorizer.fit_transform(training_comments)\n",
    "\n",
    "  # Vectorize testing set\n",
    "  x_test = vectorizer.transform(testing_comments)\n",
    "\n",
    "  # Select top 'k' of the vectorized features.\n",
    "  selector = SelectKBest(f_classif, k=min(top_k, x_train.shape[1]))\n",
    "  selector.fit(x_train, training_labels)\n",
    "  x_train = selector.transform(x_train).astype('float32')\n",
    "  x_test = selector.transform(x_test).astype('float32')\n",
    "  return x_train, x_test\n",
    "\n",
    "x_train, x_test = ngram_vectorize(reddit_train_x, reddit_train_y, reddit_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hByAaS2JOrWW"
   },
   "source": [
    "# **Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jL5mTyIsZz9B",
    "outputId": "a23a122f-08e0-43f0-ef3a-d4c34243c894"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5560714285714285"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes with top k n-gram vectors\n",
    "clf = MultinomialNB().fit(x_train, reddit_train_y)\n",
    "predict = clf.predict(x_test)\n",
    "np.mean(predict == reddit_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3875NeRKiJeM",
    "outputId": "18b34b92-265c-4a32-b06e-e07bad71aeb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5495"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm = SGDClassifier(loss=\"hinge\", penalty=\"l2\", alpha=1e-3, random_state=42, max_iter=30, tol=None).fit(x_train, reddit_train_y)\n",
    "predict_svm = svm.predict(x_test)\n",
    "np.mean(predict_svm == reddit_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "n0PJ0TsDcYjz",
    "outputId": "7529ee7f-dc33-4d95-82d0-a114575199bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5385\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logistic = LogisticRegression().fit(x_train, reddit_train_y)\n",
    "predict_logistic = logistic.predict(x_test)\n",
    "score = logistic.score(x_test, reddit_test_y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NoLsLWdj88QH"
   },
   "source": [
    "# **Pre-trained embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S11kurzBMNKx"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet gensim\n",
    "\n",
    "# To add to Drive\n",
    "# https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8FlTZk7iO7Y0",
    "outputId": "0b7a55d3-a2fc-48bd-bfc1-5bab5c7244eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "path_word2vec = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "print(path_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "Gt3B3Gb4RXGJ",
    "outputId": "42a3e5c3-da8f-4826-ebe8-e59268fdb4b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Load vectors directly from the file\n",
    "model = KeyedVectors.load_word2vec_format(path_word2vec, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGjrvw4YSpVe"
   },
   "outputs": [],
   "source": [
    "import string \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def make_new_data(data_input):\n",
    "  new_data = ['' for i in range(len(data_input))]\n",
    "  for index, doc in enumerate(data_input):\n",
    "    doc = doc.lower()\n",
    "    doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
    "    for word in doc.split():\n",
    "      if word not in stop_words:\n",
    "        new_data[index] += word + \" \"\n",
    "  return new_data\n",
    "\n",
    "new_train_data = make_new_data(reddit_train_x)\n",
    "new_test_data = make_new_data(reddit_test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "OLvgJ3kOMPhD",
    "outputId": "9b6be767-645e-471f-ee63-d58985b500cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHSHSHSHS not in sentence\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Access vectors for specific words with a keyed lookup:\n",
    "vector = model['easy']\n",
    "# see the shape of the vector (300,)\n",
    "vector.shape\n",
    "# Processing sentences is not as simple as with Spacy:\n",
    "\n",
    "vectors = [0] * 300\n",
    "sentence = \"This is some text I am processing with Spacy SHSHSHSHS\"\n",
    "count = 0\n",
    "for word in sentence.split(' '):\n",
    "  if word in model.vocab:\n",
    "    vectors += model[word]\n",
    "    count += 1\n",
    "  else:\n",
    "    print(word, \"not in sentence\")\n",
    "vectors /= count\n",
    "\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "4cae7pbbZ27e",
    "outputId": "83728255-0fc8-4aab-93b3-3e9b53ca3e34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('straightforward', 0.7460168600082397),\n",
       " ('Simple', 0.7108173966407776),\n",
       " ('uncomplicated', 0.6297484636306763),\n",
       " ('simplest', 0.6171397566795349),\n",
       " ('easy', 0.5990299582481384),\n",
       " ('fairly_straightforward', 0.5893307328224182),\n",
       " ('deceptively_simple', 0.5743066072463989),\n",
       " ('simpler', 0.5537199378013611),\n",
       " ('simplistic', 0.5516539216041565),\n",
       " ('disarmingly_simple', 0.5365327000617981)]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LiRg3mNVEUlp"
   },
   "outputs": [],
   "source": [
    "def embeddings(data):\n",
    "  embed = np.zeros((len(data), 300))\n",
    "  # donne une phrase (doc)\n",
    "  for index, doc in enumerate(data):\n",
    "    count = 0\n",
    "    # pour chaque mot dans le document\n",
    "    for i, word in enumerate(doc.split()):\n",
    "      if word in model.vocab:\n",
    "        embed[index] += model[word]\n",
    "        count += 1\n",
    "      #else:\n",
    "      #  print(\"\\n\", word, \" not in sentence\\n\")\n",
    "    # avoir la moyenne d'embeddings pour le document\n",
    "    if count == 0:\n",
    "      # no word found\n",
    "      continue\n",
    "    embed[index] /= count\n",
    "    print('\\r Progress %s/%s' % (index, len(data)), end=\"\")\n",
    "  return embed      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "P0tsIG4_Vzoh",
    "outputId": "43e97604-1421-4dcf-f438-25f364948a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Progress 55999/56000\n",
      " (56000, 300)\n"
     ]
    }
   ],
   "source": [
    "train_word_embed = embeddings(new_train_data)\n",
    "print(\"\\n\", train_word_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "V2IeQT2Aa-VJ",
    "outputId": "11fefdf7-4000-4355-ed77-09c87e6c9120"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06328125,  0.12769775,  0.02001038,  0.11289673, -0.02246075,\n",
       "        0.10825195,  0.11875   , -0.07305908,  0.04571533,  0.09179688,\n",
       "        0.00377197, -0.16743164, -0.05092773,  0.01308594, -0.08240356,\n",
       "        0.00649414, -0.12415771,  0.17851563,  0.02233887, -0.07890625,\n",
       "       -0.01975098,  0.00690918,  0.06424561, -0.06119385,  0.02331543,\n",
       "       -0.1355957 , -0.13981934, -0.0055542 ,  0.10153809, -0.08789062,\n",
       "        0.06328735,  0.13879395, -0.00776367, -0.00031738, -0.11497803,\n",
       "       -0.04671631,  0.21777344,  0.09018555, -0.00800781,  0.10351562,\n",
       "        0.08557129, -0.08491211,  0.2140625 , -0.025     ,  0.12358398,\n",
       "       -0.11191406, -0.0357605 , -0.00273437,  0.11337891,  0.00368805,\n",
       "       -0.09755859, -0.00600586, -0.07563477, -0.03389893, -0.05596313,\n",
       "        0.05493164,  0.06135254,  0.01606445,  0.01801147,  0.00406494,\n",
       "       -0.12299805, -0.05092773,  0.05938721, -0.04364319, -0.09420166,\n",
       "       -0.07133789,  0.05507812, -0.02626953, -0.08476562,  0.1730957 ,\n",
       "       -0.00432739, -0.15717773,  0.02824707,  0.02172852, -0.16054688,\n",
       "       -0.06713867,  0.12045898, -0.00302734,  0.02587891, -0.03271484,\n",
       "        0.09656982, -0.01894531, -0.06512451, -0.07792969, -0.17822266,\n",
       "       -0.0771759 ,  0.00769043,  0.12250671,  0.04707031,  0.12207031,\n",
       "        0.02416992,  0.01298828, -0.08632813,  0.04432373, -0.08139648,\n",
       "       -0.04916992,  0.16577148, -0.05336914,  0.05185547, -0.02978516,\n",
       "       -0.15500488, -0.06855469,  0.05008545, -0.03835068,  0.15722656,\n",
       "        0.01650391, -0.05002441, -0.0626709 , -0.01408691, -0.06928711,\n",
       "       -0.14248047, -0.15808105,  0.10166016, -0.10756836,  0.06738281,\n",
       "       -0.07358704, -0.03339844, -0.05958252,  0.03071289,  0.01557007,\n",
       "       -0.02954102,  0.00214844, -0.03708496,  0.06206055,  0.05999756,\n",
       "       -0.06433105,  0.06356201, -0.05250854,  0.04902344,  0.1017334 ,\n",
       "       -0.04443359, -0.00166016, -0.01668701,  0.08342285, -0.06981201,\n",
       "        0.04416504, -0.01552734, -0.03452148, -0.04404297,  0.1671875 ,\n",
       "        0.03374023, -0.15952148,  0.07415771,  0.07763672,  0.22539063,\n",
       "       -0.00772705, -0.09724121, -0.07626953, -0.06230469, -0.09570312,\n",
       "        0.09053955,  0.00761719, -0.19910583,  0.22773437, -0.00566406,\n",
       "       -0.02689819, -0.10848694, -0.14633789, -0.03549805,  0.09672852,\n",
       "       -0.03554687, -0.00527344,  0.02612305, -0.0564209 ,  0.00385742,\n",
       "       -0.10175781,  0.21010742, -0.13779297, -0.1392334 ,  0.03723145,\n",
       "       -0.08459473,  0.0371582 ,  0.04276123,  0.07905273, -0.0251709 ,\n",
       "        0.0456543 ,  0.01723633, -0.00083008, -0.04074707,  0.05019531,\n",
       "       -0.1583252 , -0.09965935,  0.01992187,  0.05668945, -0.01992187,\n",
       "        0.03493652, -0.06606445, -0.04390259,  0.11446533,  0.14472656,\n",
       "        0.15615234,  0.08569336,  0.03930664,  0.04345703, -0.0375885 ,\n",
       "        0.06733398,  0.01469727, -0.0539917 , -0.09490967, -0.06895523,\n",
       "        0.05625   ,  0.03566895, -0.12280273,  0.01213379,  0.17319336,\n",
       "       -0.05073242, -0.00195312,  0.02241211, -0.02687988, -0.0111084 ,\n",
       "       -0.10894775,  0.09677734, -0.0746582 , -0.03186035, -0.13256836,\n",
       "       -0.04599609, -0.03652344,  0.02575073, -0.12330322,  0.02429199,\n",
       "       -0.09521484, -0.03291016,  0.00803223, -0.03969727,  0.10192871,\n",
       "       -0.11113281, -0.00996094,  0.04508057, -0.02272949,  0.13359375,\n",
       "        0.00649414, -0.03170776, -0.02617188,  0.0802002 ,  0.06003418,\n",
       "        0.20419922, -0.10569458, -0.03304443,  0.08044434,  0.03654785,\n",
       "        0.05771484, -0.00498047, -0.01693726, -0.02597656,  0.04760742,\n",
       "        0.01213379,  0.04316406, -0.02785645, -0.06181641, -0.02597656,\n",
       "        0.03167725,  0.04385986,  0.18388672,  0.18444824,  0.05324707,\n",
       "       -0.05997314, -0.09160156, -0.06036377, -0.06546898, -0.23847656,\n",
       "       -0.04659424, -0.08903809, -0.03517761,  0.1671875 , -0.08234863,\n",
       "        0.08181152, -0.09156189, -0.04840088, -0.03666992,  0.00444336,\n",
       "        0.0130127 ,  0.16804199,  0.21206055,  0.06657715,  0.11030273,\n",
       "       -0.09912109, -0.01982422, -0.12431641, -0.08032227, -0.08447266,\n",
       "       -0.02209473,  0.01513672,  0.11757813,  0.05595703, -0.00319824,\n",
       "       -0.07431641, -0.21826172,  0.02211914,  0.0402832 ,  0.08000183,\n",
       "        0.02223969,  0.02731934, -0.12950439,  0.01538086, -0.11235352,\n",
       "       -0.03553467,  0.08300781, -0.06923828,  0.03662109,  0.03852539])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word_embed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "s2UWabyvWIz9",
    "outputId": "178b700e-6278-4005-8ce0-3d942bc22928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      " Progress 13999/14000"
     ]
    }
   ],
   "source": [
    "print(len(new_test_data))\n",
    "test_word_embed = embeddings(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "r8olIERNGQs4",
    "outputId": "5e0ee02a-b0d8-4bb6-c2c2-4b71efd8419d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3886428571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier((100, 100,))\n",
    "\n",
    "clf.fit(train_word_embed, reddit_train_y)\n",
    "\n",
    "predict = clf.predict(test_word_embed)\n",
    "score = clf.score(test_word_embed, reddit_test_y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "77Po8UeidWif",
    "outputId": "ac36585b-dbc5-4065-bfb2-2884d974a6e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3492142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm_embeddings = SGDClassifier(loss=\"hinge\", penalty=\"l2\", alpha=1e-3, random_state=42, max_iter=30, tol=None).fit(train_word_embed, reddit_train_y)\n",
    "predict_svm_embeddings = svm_embeddings.predict(test_word_embed)\n",
    "score_svm_embeddings = svm_embeddings.score(test_word_embed, reddit_test_y)\n",
    "print(score_svm_embeddings)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kaggle.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
